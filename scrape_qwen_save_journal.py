import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

from typing import *

import os
import json

from openai import OpenAI
from openai.types.chat.chat_completion import Choice

from rss import get_all_journal_articles
import re
import feedparser

from datetime import datetime, timedelta

import sqlite3
from config import FIELD_KEYWORDS, JOURNALS_CONFIG, init_database

# é…ç½®ä¿¡æ¯
CLIENT = OpenAI(
    api_key="sk-mdOUhbhns3A8LgdlmFX6DNHeUGW0zSBJHsQooum7SQH5iTRE",
    base_url="https://api.moonshot.cn/v1",
)

def identify_journal_from_link(link):
    """æ ¹æ®é“¾æ¥è¯†åˆ«æœŸåˆŠï¼Œä½¿ç”¨é…ç½®ä¸­çš„domain_patterns"""
    if not link or link == 'æ— é“¾æ¥':
        return 'æœªçŸ¥æœŸåˆŠ'
        
    # å…ˆæ£€æŸ¥ç°æœ‰æœŸåˆŠ
    for journal_id, config in JOURNALS_CONFIG.items():
        domain_patterns = config.get('domain_patterns', [])
        exclude_patterns = config.get('exclude_patterns', [])
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…domain_patternsä¸­çš„ä»»ä¸€æ¨¡å¼
        if any(pattern in link for pattern in domain_patterns):
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…exclude_patternsä¸­çš„ä»»ä¸€æ¨¡å¼
            if not any(ex_pattern in link for ex_pattern in exclude_patterns):
                return config.get('journal_name', journal_id)
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æœŸåˆŠ
    return 'æœªçŸ¥æœŸåˆŠ'

def get_detailed_abstract(entry):
    """é›†æˆæœç´¢ä¸ç¿»è¯‘ï¼ˆä¿®å¤å­—æ®µåˆå¹¶é—®é¢˜ï¼‰"""
    # ä»é“¾æ¥è§£ææœŸåˆŠåç§°
    link = getattr(entry, 'link', '')
    
    # å¦‚æœentryå·²ç»æœ‰journalå±æ€§ï¼Œä¼˜å…ˆä½¿ç”¨
    journal = getattr(entry, 'journal', None)
    if not journal:
        journal = identify_journal_from_link(link)
        
    # è¡¥å…¨entryçš„journalå±æ€§
    entry.journal = journal
    # åŸºç¡€å…ƒæ•°æ®æå–ï¼ˆå¿…é¡»å­—æ®µï¼‰
    base_data = {
        'journal': getattr(entry, 'journal', 'æœªçŸ¥æœŸåˆŠ'),
        'original_title': getattr(entry, 'title', 'æ— æ ‡é¢˜'),
        'original_authors': ', '.join(a.name for a in getattr(entry, 'authors', [])),
        'link': getattr(entry, 'link', 'æ— é“¾æ¥'),
        'publish_date': parse_entry_date(entry).strftime('%Y-%m-%d')
    }
    # search å·¥å…·çš„å…·ä½“å®ç°ï¼Œè¿™é‡Œæˆ‘ä»¬åªéœ€è¦è¿”å›å‚æ•°å³å¯
    def search_impl(arguments: Dict[str, Any]) -> Any:
    
        return arguments

    try:
        # å¢å¼ºç‰ˆç³»ç»Ÿæç¤º
        system_prompt = """ä½œä¸ºå­¦æœ¯åŠ©æ‰‹ï¼Œè¯·å®Œæˆï¼š
1. ç½‘ç»œæœç´¢è·å–ç”¨æˆ·æåˆ°çš„è®ºæ–‡æ‘˜è¦ï¼ˆ250å­—ä»¥å†…ï¼Œä¸­æ–‡ï¼‰
2. ç¿»è¯‘æ ‡é¢˜å’Œä½œè€…ä¿¡æ¯
3. ç»“æ„åŒ–è¿”å›ï¼š
{
  "original_title": "ä¿ç•™åŸå§‹æ ‡é¢˜",
  "translated_title": "ä¸­æ–‡æ ‡é¢˜",
  "original_authors": "åŸå§‹ä½œè€…åˆ—è¡¨", 
  "translated_authors": "ä¸­æ–‡ä½œè€…åˆ—è¡¨",
  "abstract": "ä¸­æ–‡æ‘˜è¦",
  "summary": "100å­—æ€»ç»“"
}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·å¤„ç†ï¼š{base_data['original_title']}"}
        ]

        finish_reason = None
        final_data = {}

        # å¤šè½®å¯¹è¯å¤„ç†ï¼ˆç¬¦åˆå®˜æ–¹æ¨¡æ¿ï¼‰
        while finish_reason is None or finish_reason == "tool_calls":
            completion = CLIENT.chat.completions.create(
                model="moonshot-v1-128k",
                messages=messages,
                temperature=0.3,
                response_format={"type": "json_object"},
                tools=[{
                    "type": "builtin_function",
                    "function": {"name": "$web_search"}
                }]
            )

            choice = completion.choices[0]
            finish_reason = choice.finish_reason

            # å·¥å…·è°ƒç”¨å¤„ç†ï¼ˆä¸¥æ ¼éµå¾ªå®˜æ–¹ç¤ºä¾‹ï¼‰
            if finish_reason == "tool_calls":
                messages.append(choice.message)
                for tool_call in choice.message.tool_calls:
                    if tool_call.function.name == "$web_search":
                        args = json.loads(tool_call.function.arguments)

                        # æ‰“å°tokenæ¶ˆè€—ï¼ˆæ–°å¢ï¼‰
                        search_tokens = args.get("usage", {}).get("total_tokens", 0)
                        print(f"æœç´¢æ¶ˆè€—tokens: {search_tokens}")

                        tool_result = search_impl(args)
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": "$web_search",
                            "content": json.dumps(tool_result)
                        })
            else:
                # è§£æç»“æ„åŒ–å“åº”
                try:
                    response = choice.message.content
                    # æ·»åŠ å®‰å…¨çš„JSONè§£æ
                    api_data = json.loads(response)
                    
                    # åˆå¹¶æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨APIæ•°æ®ï¼Œä¿ç•™åŸºç¡€å…ƒæ•°æ®ï¼‰
                    return {
                        **base_data,  # åŸºç¡€å­—æ®µ
                        'translated_title': api_data.get('translated_title', base_data['original_title']),
                        'translated_authors': api_data.get('translated_authors', base_data['original_authors']),
                        'abstract': api_data.get('abstract', 'æ‘˜è¦è·å–å¤±è´¥'),
                        'summary': api_data.get('summary', 'æ€»ç»“ç”Ÿæˆå¤±è´¥')
                    }
                except Exception as e:
                    print(f"å¤„ç†å¤±è´¥: {str(e)}")
                    # è¿”å›åŸºç¡€æ•°æ®+é”™è¯¯ä¿¡æ¯
                    return {
                        **base_data,
                        'translated_title': base_data['original_title'],
                        'translated_authors': base_data['original_authors'],
                        'abstract': 'å†…å®¹å¤„ç†å¼‚å¸¸',
                        'summary': 'å†…å®¹å¤„ç†å¼‚å¸¸'
                    }

    except Exception as e:
        print(f"âš ï¸ å…¨å±€å¼‚å¸¸: {str(e)}")
        return {
            'Translated Title': base_data['original_title'],
            'Translated Authors': base_data['original_authors'],
            'Abstract': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨'
        }

def classify_article_fields(article_data: dict) -> Dict[str, float]:
    """åˆ¤æ–­æ–‡ç« å±äºå“ªäº›é¢†åŸŸï¼Œè¿”å›é¢†åŸŸåŠç½®ä¿¡åº¦"""
    title = article_data.get('original_title', 'æ— æ ‡é¢˜')[:50]
    print(f"ğŸ” æ­£åœ¨åˆ¤æ–­ã€Š{title}...ã€‹å±äºå“ªäº›é¢†åŸŸ...")
    
    # å‡†å¤‡é¢†åŸŸåˆ—è¡¨ï¼Œæ’é™¤"æ— "
    fields = [field for field in FIELD_KEYWORDS.keys() if field != "æ— "]
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘ç ”åŠ©æ‰‹ï¼Œéœ€è¦åˆ¤æ–­è®ºæ–‡å±äºå“ªäº›ç ”ç©¶é¢†åŸŸã€‚

è®ºæ–‡ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{article_data.get('original_title', '')}
æ‘˜è¦ï¼š{article_data.get('abstract', '')[:2000]}

è¯·åˆ¤æ–­è¿™ç¯‡è®ºæ–‡å±äºä»¥ä¸‹å“ªäº›é¢†åŸŸï¼ˆå¯å¤šé€‰ï¼‰ï¼Œå¹¶ç»™å‡ºç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´çš„å°æ•°ï¼‰ï¼š
{', '.join(fields)}

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "fields": {{
    "é¢†åŸŸ1": 0.95,
    "é¢†åŸŸ2": 0.85,
    "é¢†åŸŸ3": 0.75
  }}
}}

åªè¿”å›ç½®ä¿¡åº¦å¤§äº0.5çš„é¢†åŸŸã€‚"""

    try:
        completion = CLIENT.chat.completions.create(
            model="moonshot-v1-8k",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": "è¯·åˆ†æè¿™ç¯‡è®ºæ–‡å±äºå“ªäº›é¢†åŸŸ"}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(completion.choices[0].message.content)
        field_results = result.get("fields", {})
        
        # æ‰“å°ç»“æœ
        if field_results:
            print("âœ… é¢†åŸŸåˆ†ç±»ç»“æœ:")
            for field, confidence in field_results.items():
                print(f"  - {field}: {confidence:.2f}")
        else:
            print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„é¢†åŸŸ")
            
        return field_results
        
    except Exception as e:
        print(f"âš ï¸ é¢†åŸŸåˆ¤æ–­å¤±è´¥: {str(e)}")
        return {}  # å¤±è´¥æ—¶è¿”å›ç©ºå­—å…¸

def save_to_database(df):
    """å¢å¼ºå­—æ®µéªŒè¯å¹¶ä¿å­˜æ–‡ç« åŠå…¶é¢†åŸŸåˆ†ç±»"""
    # åˆæ³•å­—æ®µåˆ—è¡¨
    valid_columns = {
        'journal', 'original_title', 'translated_title',
        'original_authors', 'translated_authors',
        'abstract', 'summary', 'link', 'publish_date'
    }
    
    # è¿‡æ»¤éæ³•å­—æ®µ
    df = df[[col for col in df.columns if col in valid_columns]]
    
    # å¿…è¦å­—æ®µæ£€æŸ¥
    required_fields = {
        'journal': 'æœªçŸ¥æœŸåˆŠ',
        'link': 'æ— é“¾æ¥',
        'publish_date': datetime.now().strftime('%Y-%m-%d')
    }
    
    try:
        conn = sqlite3.connect('journals.db')
        cursor = conn.cursor()
        
        # è·å–å½“å‰è®°å½•æ•°
        original_count = pd.read_sql_query("SELECT COUNT(*) FROM articles", conn).iloc[0,0]
        
        # ä¿å­˜æ–‡ç« å¹¶è·å–æ–°å¢æ–‡ç« çš„ID
        new_article_ids = []
        
        for _, row in df.iterrows():
            # å‡†å¤‡æ’å…¥æ•°æ®
            columns = ', '.join(row.index)
            placeholders = ', '.join(['?'] * len(row))
            
            # æ‰§è¡Œæ’å…¥
            cursor.execute(f"""
                INSERT OR IGNORE INTO articles 
                ({columns}) 
                VALUES ({placeholders})
            """, tuple(row))
            
            # å¦‚æœæ˜¯æ–°æ’å…¥çš„æ–‡ç« ï¼Œè·å–å…¶ID
            if cursor.rowcount > 0:
                article_id = cursor.lastrowid
                new_article_ids.append((article_id, row.to_dict()))
        
        conn.commit()
        
        # è·å–ä¿å­˜åçš„è®°å½•æ•°
        new_count = pd.read_sql_query("SELECT COUNT(*) FROM articles", conn).iloc[0,0]
        added = new_count - original_count
        skipped = len(df) - added
        
        print(f"ğŸ’¾ æ•°æ®åº“æ›´æ–°: æ–°å¢ {added} ç¯‡, è·³è¿‡ {skipped} ç¯‡é‡å¤")
        
        # ä¸ºæ–°å¢æ–‡ç« è¿›è¡Œé¢†åŸŸåˆ†ç±»å¹¶ä¿å­˜
        for article_id, article_data in new_article_ids:
            print(f"\nğŸ” ä¸ºæ–‡ç« ID {article_id} è¿›è¡Œé¢†åŸŸåˆ†ç±»...")
            field_results = classify_article_fields(article_data)
            
            # ä¿å­˜é¢†åŸŸåˆ†ç±»ç»“æœ
            for field, confidence in field_results.items():
                cursor.execute("""
                    INSERT OR REPLACE INTO article_fields 
                    (article_id, field, confidence) 
                    VALUES (?, ?, ?)
                """, (article_id, field, confidence))
            
            conn.commit()
            print(f"âœ… å·²ä¿å­˜ {len(field_results)} ä¸ªé¢†åŸŸåˆ†ç±»ç»“æœ")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
        raise
    finally:
        if 'conn' in locals():
            conn.close()

def article_exists(link: str, entry) -> bool:
    """å¢å¼ºå»é‡æ£€æŸ¥"""
    if not link or link == 'æ— é“¾æ¥':
        return False
        
    conn = sqlite3.connect('journals.db')
    query = "SELECT 1 FROM articles WHERE link = ? OR (journal = ? AND original_title = ?) LIMIT 1"
    params = (link, 
             getattr(entry, 'journal', 'æœªçŸ¥æœŸåˆŠ'),  # å®‰å…¨è·å–å±æ€§
             getattr(entry, 'title', 'æ— æ ‡é¢˜'))
    result = pd.read_sql_query(query, conn, params=params)
    conn.close()
    return not result.empty

def get_rss_articles(articles_num=3):
    """è·å–å¹¶å¤„ç†æœŸåˆŠæ–‡ç« ï¼ˆå¢å¼ºæ—¥å¿—è¾“å‡ºï¼‰"""
    print(f"\nğŸ” å¼€å§‹è·å–æœ€æ–°æ–‡ç« ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M')}ï¼‰")
    all_articles = []
    
    entries = get_all_journal_articles(articles_num)
    total = len(entries)
    print(f"ğŸ“¥ å…±å‘ç° {total} ç¯‡å€™é€‰æ–‡ç« ")
    
    # æ–°å¢å­—å…¸æ¥å­˜å‚¨æ¯ä¸ªæœŸåˆŠçš„æ ‡é¢˜å’Œæ•°é‡
    journal_count = {}

    for idx, entry in enumerate(entries, 1):
        try:
            # è¿›åº¦æ˜¾ç¤º
            progress = f"[{idx}/{total}]"
            
            # åŸºç¡€ä¿¡æ¯
            title = getattr(entry, 'title', 'æ— æ ‡é¢˜')[:40] + "..." 
            link = getattr(entry, 'link', 'æ— é“¾æ¥')
            journal = getattr(entry, 'journal', 'æœªçŸ¥æœŸåˆŠ')  # è·å–æœŸåˆŠåç§°
            print(f"\n{progress} ğŸ“„ å¤„ç†æ–‡ç« : {title}")
            print(f"ğŸ”— æ–‡ç« é“¾æ¥: {link}")
            
            # æ£€æŸ¥é‡å¤
            if article_exists(link, entry):
                print("â© è·³è¿‡é‡å¤æ–‡ç« ")
                continue
                
            # å¤„ç†æµç¨‹
            start_time = time.time()
            processed_data = get_detailed_abstract(entry)
            elapsed = time.time() - start_time
            
            if processed_data:
                print(f"âœ… å¤„ç†æˆåŠŸï¼ˆè€—æ—¶{elapsed:.1f}sï¼‰")
                # æ˜¾ç¤ºæ–‡ç« åŸºæœ¬ä¿¡æ¯
                print(f"  æœŸåˆŠ: {processed_data.get('journal', 'æœªçŸ¥')}")
                print(f"  æ ‡é¢˜: {processed_data.get('translated_title', 'æ— æ ‡é¢˜')[:50]}...")
                df = pd.DataFrame([processed_data])
                save_to_database(df)
                all_articles.append(processed_data)

                # æ›´æ–°æœŸåˆŠè®¡æ•°
                if journal in journal_count:
                    journal_count[journal] += 1
                else:
                    journal_count[journal] = 1
            else:
                print("âš ï¸ å¤„ç†å¤±è´¥ï¼Œä¿ç•™åŸºç¡€ä¿¡æ¯")
                all_articles.append({
                    'original_title': title,
                    'link': link,
                    'publish_date': datetime.now().strftime('%Y-%m-%d')
                })
                
        except Exception as e:
            print(f"âŒ ä¸¥é‡é”™è¯¯: {str(e)}")
            continue
            
    print(f"\nğŸ“Š æœ€ç»ˆå¤„ç†å®Œæˆï¼šæˆåŠŸ {len(all_articles)} ç¯‡ï¼Œå¤±è´¥ {total - len(all_articles)} ç¯‡")
    
    # è¾“å‡ºæ¯ä¸ªæœŸåˆŠè·å–åˆ°çš„æ•°æ®æ¡æ•°å’Œå¯¹åº”æ ‡é¢˜
    print("\nğŸ“š å„æœŸåˆŠè·å–åˆ°çš„æ•°æ®æ¡æ•°ï¼š")
    for journal, count in journal_count.items():
        print(f"{journal}: {count} æ¡")

    return pd.DataFrame(all_articles)

def parse_entry_date(entry):
    """å¢å¼ºæ—¥æœŸè§£æå¯é æ€§"""
    try:
        # ä¼˜å…ˆä½¿ç”¨å·²è§£æçš„æ—¥æœŸ
        if hasattr(entry, 'published_parsed'):
            return datetime(*entry.published_parsed[:6])
            
        # å¤‡é€‰æ—¥æœŸå­—æ®µ
        date_str = getattr(entry, 'published', '') or \
                  getattr(entry, 'updated', '') or \
                  getattr(entry, 'created', '')
                  
        if not date_str:
            return datetime.now()
            
        # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
        for fmt in ('%a, %d %b %Y %H:%M:%S %Z',
                   '%Y-%m-%dT%H:%M:%SZ',
                   '%Y-%m-%d %H:%M:%S',
                   '%Y-%m-%d'):
            try:
                return datetime.strptime(date_str, fmt)
            except:
                continue
        return datetime.now()
    except:
        return datetime.now()

def is_related_to_field(article_data: dict, target_field: str) -> bool:
    """åˆ¤æ–­æ–‡ç« æ˜¯å¦å±äºç‰¹å®šé¢†åŸŸï¼ˆä»æ•°æ®åº“æŸ¥è¯¢ï¼‰"""
    # è·å–æ–‡ç« ID
    article_id = get_article_id(article_data.get('link', ''))
    if not article_id:
        # å¦‚æœæ‰¾ä¸åˆ°æ–‡ç« IDï¼Œä½¿ç”¨æ—§æ–¹æ³•è¿›è¡Œåˆ¤æ–­
        return legacy_is_related_to_field(article_data, target_field)
    
    # ä»æ•°æ®åº“æŸ¥è¯¢
    conn = sqlite3.connect('journals.db')
    cursor = conn.cursor()
    cursor.execute("""
        SELECT confidence FROM article_fields 
        WHERE article_id = ? AND field = ?
    """, (article_id, target_field))
    result = cursor.fetchone()
    conn.close()
    
    if result:
        confidence = result[0]
        print(f"ğŸ” æ–‡ç« ä¸é¢†åŸŸ {target_field} çš„ç›¸å…³åº¦: {confidence:.2f}")
        return confidence > 0.5
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æ–‡ç« ä¸é¢†åŸŸ {target_field} çš„å…³è”è®°å½•")
        return False

def get_article_id(link: str) -> int:
    """æ ¹æ®é“¾æ¥è·å–æ–‡ç« ID"""
    if not link:
        return None
        
    conn = sqlite3.connect('journals.db')
    cursor = conn.cursor()
    cursor.execute("SELECT id FROM articles WHERE link = ?", (link,))
    result = cursor.fetchone()
    conn.close()
    
    return result[0] if result else None

def legacy_is_related_to_field(article_data: dict, target_field: str) -> bool:
    """æ—§ç‰ˆé¢†åŸŸåˆ¤æ–­æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰"""
    title = article_data.get('original_title', 'æ— æ ‡é¢˜')[:50]
    print(f"ğŸ” æ­£åœ¨åˆ¤æ–­ã€Š{title}...ã€‹æ˜¯å¦å±äº {target_field} é¢†åŸŸ...", end='')
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘ç ”åŠ©æ‰‹ï¼Œéœ€è¦åˆ¤æ–­è®ºæ–‡æ˜¯å¦å±äºç‰¹å®šç ”ç©¶é¢†åŸŸã€‚
    
ç›®æ ‡é¢†åŸŸï¼š{target_field}
è®ºæ–‡ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{article_data.get('original_title', '')}
æ‘˜è¦ï¼š{article_data.get('abstract', '')[:2000]}  # é™åˆ¶é•¿åº¦é¿å…è¶…token

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è§„åˆ™åˆ¤æ–­ï¼š
1. å¦‚æœè®ºæ–‡æ˜æ˜¾å±äº{target_field}é¢†åŸŸï¼Œè¿”å›Y
2. å¦‚æœä¸ç¡®å®šæˆ–ä¸å±äºï¼Œè¿”å›N
3. åªéœ€è¿”å›å•ä¸ªå­—æ¯ï¼Œä¸è¦ä»»ä½•è§£é‡Š"""

    try:
        completion = CLIENT.chat.completions.create(
            model="moonshot-v1-8k",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": "è¯·åˆ¤æ–­è¿™ç¯‡è®ºæ–‡æ˜¯å¦å±äºç›®æ ‡é¢†åŸŸ"}
            ],
            temperature=0.1,
            max_tokens=1
        )
        result = completion.choices[0].message.content.strip().upper() == 'Y'
        print("âœ… å±äº" if result else "âŒ ä¸å±äº")
        return result
        
    except Exception as e:
        print(f"âš ï¸ åˆ¤æ–­å¤±è´¥: {str(e)}")
        return False  # å¤±è´¥æ—¶é»˜è®¤ä¿ç•™

if __name__ == "__main__":
    # ç¡®ä¿æ•°æ®åº“å­˜åœ¨
    if not os.path.exists('journals.db'):
        init_database()
    # åªæ‰§è¡ŒæŠ“å–å’Œä¿å­˜
    get_rss_articles()
    print("âœ… æ•°æ®æŠ“å–å’Œä¿å­˜å®Œæˆ")
